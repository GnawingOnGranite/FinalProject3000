# -*- coding: utf-8 -*-
"""Clean Group Project - Credit Card Fraud Detection"""

# === SETUP ===
from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import time
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score
)

# === LOAD DATA ===
data = pd.read_csv('/content/drive/MyDrive/creditcard.csv')
data = data.dropna(subset=['Class'])  # remove rows missing target
X = data.drop(columns=['Class'])
y = data['Class']

# === SPLIT DATA ===
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)

# === FILL & SCALE ===
X_train = X_train.fillna(X_train.mean())
X_val = X_val.fillna(X_val.mean())
X_test = X_test.fillna(X_test.mean())
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# === HELPER FUNCTION (UPDATED) ===
def evaluate_model(name, model, X_test, y_test):
    """Evaluate model performance (timing isolated, includes ROC/AUC)."""
    # --- TIMING BLOCK (prediction only) ---
    start_time = time.time()
    y_pred = model.predict(X_test)
    end_time = time.time()
    test_time = (end_time - start_time) * 1000  # milliseconds

    # --- METRICS ---
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    cm = confusion_matrix(y_test, y_pred)

    # --- ROC & AUC ---
    try:
        # use predict_proba if available, else decision_function
        if hasattr(model, "predict_proba"):
            y_scores = model.predict_proba(X_test)[:, 1]
        elif hasattr(model, "decision_function"):
            y_scores = model.decision_function(X_test)
        else:
            y_scores = y_pred  # fallback (for models lacking prob output)
        auc = roc_auc_score(y_test, y_scores)
    except Exception:
        auc = float('nan')

    # --- DISPLAY RESULTS ---
    print(f"\nðŸ“Š {name} Results")
    print("----------------------")
    print(f"Confusion Matrix:\n{cm}")
    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall:    {rec:.4f}")
    print(f"F1-Score:  {f1:.4f}")
    print(f"AUC:       {auc:.4f}")
    print(f"Test Time: {test_time:.2f} ms")

    # --- RETURN FOR TABLE ---
    return {
        "Model": name,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1": f1,
        "AUC": auc,
        "Test Time (ms)": test_time
    }

# === MODELS ===
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

results = []

# --- SVM ---
svm_model = SVC(kernel='rbf', random_state=42)
svm_model.fit(X_train_scaled, y_train)
results.append(evaluate_model("SVM (RBF)", svm_model, X_test_scaled, y_test))

# --- Logistic Regression ---
log_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
log_model.fit(X_train_scaled, y_train)
results.append(evaluate_model("Logistic Regression", log_model, X_test_scaled, y_test))

# --- KNN ---
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled, y_train)
results.append(evaluate_model("K-Nearest Neighbors", knn_model, X_test_scaled, y_test))

# --- Random Forest ---
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)
results.append(evaluate_model("Random Forest", rf_model, X_test_scaled, y_test))

# --- MLP Neural Network ---
mlp_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=100, random_state=42)
mlp_model.fit(X_train_scaled, y_train)
results.append(evaluate_model("MLP Neural Network", mlp_model, X_test_scaled, y_test))

# === COMPARISON TABLE ===
results_df = pd.DataFrame(results)
print("\n=== Final Model Comparison ===")
display(results_df)
